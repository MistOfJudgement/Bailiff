export MODEL=~/github/llama.cpp/models/7B/ggml-model-q4_0.bin
python3 -m llama_cpp.server